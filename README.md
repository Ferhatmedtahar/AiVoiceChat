# Real-time Voice Assistant with Next.js and ElevenLabs

This project demonstrates how to build a real-time voice assistant using **Next.js** and the **ElevenLabs Conversational SDK**.

## Features

- Real-time voice interactions using ElevenLabs AI.
- Adjustable microphone volume with mute/unmute functionality.
- User-friendly UI built with Next.js and styled components.

---

## Prerequisites

1. An ElevenLabs account.

   - Go to [ElevenLabs Conversational AI](https://elevenlabs.io/app/conversational-ai/).
   - Create and customize your AI agent.
   - Copy the **API Key** for your agent.

2. Node.js and npm installed on your local machine.

---

## Setup Instructions

1. Clone this repository:
   ```bash
   git clone https://github.com/Ferhatmedtahar/AiVoiceChat.git
   cd AiVoiceChat
   ```

```bash
npm i
npm run dev

```

## Usage

- Allow microphone access when prompted.
- Use the buttons in the UI to start or end conversations.
- Adjust volume or mute/unmute the microphone as needed.

---

## Notes

- Ensure microphone access is granted in your browser settings.
- Volume controls are restricted to a range of 0 (minimum) to 1 (maximum).

---

## Dependencies

- [Next.js](https://nextjs.org/)
- [ElevenLabs Conversational SDK](https://elevenlabs.io/docs/api-reference/introduction)
- [Lucide Icons](https://lucide.dev/)
- [Tailwind CSS](https://tailwindcss.com/)
